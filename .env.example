# SenseCAP Local Server Configuration
# Copy this file to .env and adjust the values

# Server Configuration
SERVER_PORT=8834

# Authentication Token
# Set a strong random token for production
AUTH_TOKEN=your-secret-token-here

# AI Model Configuration
# These models will be automatically pulled by Ollama on first use
OLLAMA_MODEL=llama3.1:8b-instruct-q4_1
LLAVA_MODEL=llava:7b

# API Configuration
# Used for task flow callbacks
API_HOST=localhost
API_SCHEMA=http

# Optional: Override AI service URLs (for development)
# WHISPER_URL=http://localhost:8835
# PIPER_URL=http://localhost:8835
# OLLAMA_URL=http://localhost:11434
